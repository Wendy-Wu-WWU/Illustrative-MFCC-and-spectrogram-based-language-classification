{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/te_pana/Pictures/LID'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import sklearn\n",
    "import itertools\n",
    "import keras\n",
    "import time\n",
    "from keras import applications\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import (Lambda,GlobalAveragePooling1D, BatchNormalization, Conv1D, Dense, Input, TimeDistributed, Activation, Bidirectional, SimpleRNN, GRU, LSTM)\n",
    "from keras.models import load_model\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.regularizers import l2,l1\n",
    "from keras import optimizers\n",
    "\n",
    "import random\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "#from utils.model_utils import *\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_WIDTH = 860\n",
    "IMAGE_CHANNEL = 1\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALIDATION_BATCH_SIZE = 32\n",
    "NUM_TRAIN_EPOCHS = 480\n",
    "\n",
    "TRAINED_MODEL_FILE_NAME = \"path-to-model/Lang_classification-2-epoch-{epoch:2d}-val_acc-{val_acc:.2f}-val_loss-{val_loss:.2f}.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Shuffiling Train  0_Dudley South - General Election Declaration_Chunk_100000__Pitch_1_2_Chunk_20000_.jpg\n",
      "After Shuffiling  Train  2_org_财经追击 News Report on Lunar New Year and Population 2013 in Mandarin-MbvA1J1OHjw_Chunk_450000_Chunk_10000_.jpg\n",
      "Before Shuffiling Val    1_Japanese Movie 'ShodouGirlsーBlueBlueSky'　(English Subtitled)-5GP7MwkKcF0Chunk_578_.jpg\n",
      "After Shuffiling  Val    1_Japanese Movie 'ShodouGirlsーBlueBlueSky'　(English Subtitled)-5GP7MwkKcF0Chunk_336_.jpg\n"
     ]
    }
   ],
   "source": [
    "train_path = 'path-to-training-dataset'\n",
    "val_path = 'path-to-testing-dataset'\n",
    "# train_path = '/home/te_pana/Pictures/LID/Validation_spc/'\n",
    "train_samples = list()\n",
    "validation_samples = list()\n",
    "\n",
    "for root, directories, files in os.walk(train_path):\n",
    "    for filename in files:\n",
    "        train_samples.append(filename)\n",
    "\n",
    "shuffle(train_samples)\n",
    "shuffle(train_samples)\n",
    "shuffle(train_samples)\n",
    "\n",
    "\n",
    "\n",
    "for root, directories, files in os.walk(val_path):\n",
    "    for filename in files:\n",
    "        validation_samples.append(filename)\n",
    "\n",
    "# train, test = train_test_split(samples, train_size = 0.96)\n",
    "# for root, directories, files in os.walk(val_path):\n",
    "#     for filename in files:\n",
    "#         validation_samples.append(filename)\n",
    "\n",
    "print(\"Before Shuffiling Train  \" + train_samples[20])\n",
    "shuffle(train_samples)\n",
    "print(\"After Shuffiling  Train  \" + train_samples[20])\n",
    "\n",
    "print(\"Before Shuffiling Val    \" + validation_samples[20])\n",
    "shuffle(validation_samples)\n",
    "shuffle(validation_samples)\n",
    "shuffle(validation_samples)\n",
    "print(\"After Shuffiling  Val    \" + validation_samples[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2345 125712\n"
     ]
    }
   ],
   "source": [
    "print( len(validation_samples) , len(train_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(samples, path, batch_size):\n",
    "    shuffle(samples)\n",
    "    while(1):\n",
    "        \n",
    "        for x in range(0,len(samples),batch_size):\n",
    "            Input_Image1 = []\n",
    "            Input_label1 = []     \n",
    "            \n",
    "            for Image in samples[x:x+batch_size]:\n",
    "                img = cv2.imread(path+Image, 0)\n",
    "                img = img.reshape(IMAGE_CHANNEL, IMAGE_WIDTH, IMAGE_HEIGHT)\n",
    "                label = Image.split(\"_\")[0]\n",
    "                label = np.eye(num_classes)[int(label)]\n",
    "                Input_Image1.append(img[0])\n",
    "                Input_label1.append(label)\n",
    "                \n",
    "            X_train = np.array(Input_Image1)\n",
    "            y_train = np.array(Input_label1)\n",
    "            \n",
    "            yield sklearn.utils.shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = generator(samples = train_samples, path = train_path, batch_size = TRAIN_BATCH_SIZE)\n",
    "valid_generator = generator(samples = validation_samples, path = val_path, batch_size = VALIDATION_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def cnn_rnn(input_dim, filters, kernel_size, conv_stride,\n",
    "    conv_border_mode, units, output_dim=3):\n",
    "    \"\"\" Build a recurrent + convolutional network for speech \n",
    "    \"\"\"\n",
    "    # Main acoustic input\n",
    "    input_data = Input(name='the_input', shape=(IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "    input_data1 = Lambda(lambda x: x/255.0)(input_data)\n",
    "    # Add convolutional layer\n",
    "    conv_1d = Conv1D(filters, kernel_size, \n",
    "                     strides=conv_stride, \n",
    "                     padding=conv_border_mode,\n",
    "                     activation='relu',\n",
    "                     name='conv1d')(input_data1)\n",
    "    # Add batch normalization\n",
    "    bn_cnn = BatchNormalization(name='bn_conv_1d')(conv_1d)\n",
    "    # Add a recurrent layer\n",
    "    simp_rnn = GRU(units, activation='relu',\n",
    "        return_sequences=True, implementation=2, name='rnn')(bn_cnn)\n",
    "    # TODO: Add batch normalization\n",
    "    bn_rnn = BatchNormalization(name='bn_rnn_1d')(simp_rnn)\n",
    "    # TODO: Add a TimeDistributed(Dense(output_dim)) layer\n",
    "    time_dense = TimeDistributed(Dense(output_dim))(bn_rnn)\n",
    "    # Add softmax activation layer\n",
    "#     a = Flatten()(time_dense)\n",
    "    y_pred1 =  GlobalAveragePooling1D()(time_dense)\n",
    "#     y_pred1 = Dense(3)(time_dense)\n",
    "    y_pred = Activation('softmax', name='softmax')(y_pred1)\n",
    "    \n",
    "\n",
    "    # Specify the model\n",
    "    model = Model(inputs=input_data, outputs=y_pred)\n",
    "    model.output_length = lambda x: cnn_output_length(\n",
    "        x, kernel_size, conv_border_mode, conv_stride)\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_rnn(input_dim, units, recur_layers, output_dim=29):\n",
    "    \"\"\" Build a deep recurrent network for speech \n",
    "    \"\"\"\n",
    "    # Main acoustic input\n",
    "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
    "    if recur_layers == 1:\n",
    "        layer = LSTM(units, return_sequences=True, activation='relu')(input_data)\n",
    "        layer = BatchNormalization(name='bt_rnn_1')(layer)\n",
    "    else:\n",
    "        layer = LSTM(units, return_sequences=True, activation='relu')(input_data)\n",
    "        layer = BatchNormalization(name='bt_rnn_1')(layer)\n",
    "\n",
    "        for i in range(recur_layers - 2):\n",
    "            layer = LSTM(units, return_sequences=True, activation='relu')(layer)\n",
    "            layer = BatchNormalization(name='bt_rnn_{}'.format(2+i))(layer)\n",
    "\n",
    "        layer = LSTM(units, return_sequences=True, activation='relu')(layer)\n",
    "        layer = BatchNormalization(name='bt_rnn_last_rnn')(layer)\n",
    "\n",
    "    \n",
    "    time_dense = TimeDistributed(Dense(output_dim))(layer)\n",
    "    # Add softmax activation layer\n",
    "    y_pred = Activation('softmax', name='softmax')(time_dense)\n",
    "    # Specify the model\n",
    "    model = Model(inputs=input_data, outputs=y_pred)\n",
    "    model.output_length = lambda x: x\n",
    "    print(model.summary())\n",
    "return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bidirectional_network(input_dim, units, output_dim=29):\n",
    "    \"\"\" Build a bidirectional recurrent network for speech\n",
    "    \"\"\"\n",
    "    # Main acoustic input\n",
    "    input_data = Input(name='the_input', shape=(None, input_dim))\n",
    "    bidir_rnn = Bidirectional(LSTM(units, return_sequences=True, activation='relu'), merge_mode='concat')(input_data)\n",
    "    time_dense = TimeDistributed(Dense(output_dim))(bidir_rnn)\n",
    "    # Add softmax activation layer\n",
    "    y_pred = Activation('softmax', name='softmax')(time_dense)\n",
    "    # Specify the model\n",
    "    model = Model(inputs=input_data, outputs=y_pred)\n",
    "    model.output_length = lambda x: x\n",
    "    print(model.summary())\n",
    "return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "the_input (InputLayer)       (None, 860, 256)          0         \n",
      "_________________________________________________________________\n",
      "lambda_1 (Lambda)            (None, 860, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 425, 200)          563400    \n",
      "_________________________________________________________________\n",
      "bn_conv_1d (BatchNormalizati (None, 425, 200)          800       \n",
      "_________________________________________________________________\n",
      "rnn (GRU)                    (None, 425, 200)          240600    \n",
      "_________________________________________________________________\n",
      "bn_rnn_1d (BatchNormalizatio (None, 425, 200)          800       \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 425, 3)            603       \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 3)                 0         \n",
      "_________________________________________________________________\n",
      "softmax (Activation)         (None, 3)                 0         \n",
      "=================================================================\n",
      "Total params: 806,203\n",
      "Trainable params: 805,403\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = cnn_rnn(input_dim=(860,256), # change to what ever model you want to use--> here cnn_rnn model is used\n",
    "                        filters=200,\n",
    "                        kernel_size=11, \n",
    "                        conv_stride=2,\n",
    "                        conv_border_mode='valid',\n",
    "                        units=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/480\n",
      "983/982 [==============================] - 1714s - loss: 0.9778 - acc: 0.5201 - val_loss: 2.6715 - val_acc: 0.2891\n",
      "Epoch 2/480\n",
      "243/982 [======>.......................] - ETA: 1272s - loss: 0.8560 - acc: 0.6128"
     ]
    }
   ],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=TRAINED_MODEL_FILE_NAME)\n",
    "model.fit_generator(train_generator, steps_per_epoch= (len(train_samples)/(TRAIN_BATCH_SIZE*4)),\n",
    "            validation_data=valid_generator, validation_steps=len(validation_samples)/VALIDATION_BATCH_SIZE,\n",
    "           epochs=NUM_TRAIN_EPOCHS, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adadelta',metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = load_model(\"/media/te_pana/Disk2/Others/LID/LID-2-epoch-21-val_acc-0.90-val_loss-0.47.h5\")\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath=TRAINED_MODEL_FILE_NAME)\n",
    "model.fit_generator(train_generator, steps_per_epoch= (len(train)/(TRAIN_BATCH_SIZE)),\n",
    "            validation_data=valid_generator, validation_steps=len(test)/VALIDATION_BATCH_SIZE,\n",
    "           epochs=NUM_TRAIN_EPOCHS, callbacks = [checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Epoch 1/480\n",
    "3010/3010 [==============================] - 3160s - loss: 0.6778 - acc: 0.7055 - val_loss: 0.8993 - val_acc: 0.6495\n",
    "Epoch 2/480\n",
    "3010/3010 [==============================] - 3156s - loss: 0.4718 - acc: 0.8129 - val_loss: 1.1379 - val_acc: 0.5430\n",
    "Epoch 3/480\n",
    "3010/3010 [==============================] - 3164s - loss: 0.3655 - acc: 0.8588 - val_loss: 0.6176 - val_acc: 0.7829\n",
    "Epoch 4/480\n",
    "3010/3010 [==============================] - 3161s - loss: 0.3017 - acc: 0.8848 - val_loss: 0.6285 - val_acc: 0.7509\n",
    "Epoch 5/480\n",
    "3010/3010 [==============================] - 3161s - loss: 0.2581 - acc: 0.9038 - val_loss: 0.3857 - val_acc: 0.8547\n",
    "Epoch 6/480\n",
    "3010/3010 [==============================] - 3161s - loss: 0.2208 - acc: 0.9187 - val_loss: 0.6774 - val_acc: 0.7361\n",
    "Epoch 7/480\n",
    "3010/3010 [==============================] - 3161s - loss: 0.1908 - acc: 0.9311 - val_loss: 0.2863 - val_acc: 0.8912\n",
    "Epoch 8/480\n",
    "3010/3010 [==============================] - 3161s - loss: 0.1683 - acc: 0.9401 - val_loss: 1.5436 - val_acc: 0.5864\n",
    "Epoch 9/480\n",
    "3010/3010 [==============================] - 3162s - loss: 0.1694 - acc: 0.9395 - val_loss: 0.8218 - val_acc: 0.7186\n",
    "Epoch 10/480\n",
    "3010/3010 [==============================] - 3164s - loss: 0.1469 - acc: 0.9476 - val_loss: 0.9280 - val_acc: 0.7257\n",
    "Epoch 11/480\n",
    "3010/3010 [==============================] - 3163s - loss: 0.1331 - acc: 0.9528 - val_loss: 1.3247 - val_acc: 0.5799\n",
    "Epoch 12/480\n",
    "3010/3010 [==============================] - 3163s - loss: 0.1274 - acc: 0.9550 - val_loss: 0.2721 - val_acc: 0.9030\n",
    "Epoch 13/480\n",
    "3010/3010 [==============================] - 3163s - loss: 0.1216 - acc: 0.9572 - val_loss: 0.7464 - val_acc: 0.7761\n",
    "Epoch 14/480\n",
    "3010/3010 [==============================] - 3162s - loss: 0.1116 - acc: 0.9609 - val_loss: 0.5203 - val_acc: 0.8250\n",
    "Epoch 15/480\n",
    "3010/3010 [==============================] - 3162s - loss: 0.0995 - acc: 0.9653 - val_loss: 0.6543 - val_acc: 0.8131\n",
    "Epoch 16/480\n",
    "3010/3010 [==============================] - 3162s - loss: 0.0904 - acc: 0.9683 - val_loss: 0.7863 - val_acc: 0.7837\n",
    "Epoch 17/480\n",
    "3010/3010 [==============================] - 3163s - loss: 0.0869 - acc: 0.9702 - val_loss: 0.3568 - val_acc: 0.8954\n",
    "Epoch 18/480\n",
    "3010/3010 [==============================] - 3162s - loss: 0.0839 - acc: 0.9714 - val_loss: 0.5483 - val_acc: 0.8587\n",
    "Epoch 19/480\n",
    "3010/3010 [==============================] - 3163s - loss: 0.0768 - acc: 0.9740 - val_loss: 0.3787 - val_acc: 0.8688\n",
    "Epoch 20/480\n",
    "3010/3010 [==============================] - 3162s - loss: 0.0695 - acc: 0.9760 - val_loss: 1.1309 - val_acc: 0.7591\n",
    "Epoch 21/480\n",
    "3010/3010 [==============================] - 3186s - loss: 0.0639 - acc: 0.9777 - val_loss: 0.6576 - val_acc: 0.8724\n",
    "Epoch 22/480\n",
    "3010/3010 [==============================] - 3350s - loss: 0.0624 - acc: 0.9787 - val_loss: 0.4688 - val_acc: 0.9022\n",
    "Epoch 23/480\n",
    "1781/3010 [================>.............] - ETA: 1272s - loss: 0.0599 - acc: 0.9793\n",
    "            \n",
    "            \n",
    "Epoch 1/480\n",
    "3010/3010 [==============================] - 3174s - loss: 0.0924 - acc: 0.9681 - val_loss: 1.0544 - val_acc: 0.7352\n",
    "Epoch 2/480\n",
    "3010/3010 [==============================] - 3180s - loss: 0.0783 - acc: 0.9726 - val_loss: 0.1891 - val_acc: 0.9294\n",
    "Epoch 3/480\n",
    "3010/3010 [==============================] - 3170s - loss: 0.0711 - acc: 0.9755 - val_loss: 0.2946 - val_acc: 0.9105\n",
    "Epoch 4/480\n",
    "3010/3010 [==============================] - 3170s - loss: 0.0665 - acc: 0.9770 - val_loss: 1.3096 - val_acc: 0.6007\n",
    "Epoch 5/480\n",
    "3010/3010 [==============================] - 3174s - loss: 0.0609 - acc: 0.9790 - val_loss: 0.3842 - val_acc: 0.8905\n",
    "Epoch 6/480\n",
    "3010/3010 [==============================] - 3207s - loss: 0.0621 - acc: 0.9791 - val_loss: 1.1011 - val_acc: 0.6243\n",
    "Epoch 7/480\n",
    "  59/3010 [..............................] - ETA: 3065s - loss: 0.0557 - acc: 0.9817"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Epoch 1/48\n",
    "118/117 [==============================] - 66s - loss: 1.0640 - acc: 0.4167 - val_loss: 1.1140 - val_acc: 0.4846\n",
    "Epoch 2/48\n",
    "118/117 [==============================] - 65s - loss: 1.0275 - acc: 0.4655 - val_loss: 1.2309 - val_acc: 0.2469\n",
    "Epoch 3/48\n",
    "118/117 [==============================] - 64s - loss: 0.9708 - acc: 0.5231 - val_loss: 1.2130 - val_acc: 0.2809\n",
    "Epoch 4/48\n",
    "118/117 [==============================] - 64s - loss: 0.8971 - acc: 0.5935 - val_loss: 1.3103 - val_acc: 0.3457\n",
    "Epoch 5/48\n",
    "118/117 [==============================] - 64s - loss: 0.7958 - acc: 0.6585 - val_loss: 1.3534 - val_acc: 0.3025\n",
    "Epoch 6/48\n",
    "118/117 [==============================] - 64s - loss: 0.7033 - acc: 0.7182 - val_loss: 1.4585 - val_acc: 0.3025\n",
    "Epoch 7/48\n",
    "118/117 [==============================] - 65s - loss: 0.6196 - acc: 0.7500 - val_loss: 1.6011 - val_acc: 0.2994\n",
    "Epoch 8/48\n",
    "118/117 [==============================] - 63s - loss: 0.5301 - acc: 0.7978 - val_loss: 1.6273 - val_acc: 0.4105\n",
    "Epoch 9/48\n",
    "118/117 [==============================] - 63s - loss: 0.4852 - acc: 0.8166 - val_loss: 1.6836 - val_acc: 0.3858\n",
    "Epoch 10/48\n",
    "118/117 [==============================] - 63s - loss: 0.4357 - acc: 0.8345 - val_loss: 1.5260 - val_acc: 0.4043\n",
    "Epoch 11/48\n",
    "118/117 [==============================] - 62s - loss: 0.3886 - acc: 0.8596 - val_loss: 1.6285 - val_acc: 0.4012\n",
    "Epoch 12/48\n",
    "118/117 [==============================] - 62s - loss: 0.3622 - acc: 0.8712 - val_loss: 1.6640 - val_acc: 0.3889\n",
    "Epoch 13/48\n",
    "118/117 [==============================] - 62s - loss: 0.3209 - acc: 0.8879 - val_loss: 1.6548 - val_acc: 0.4136\n",
    "Epoch 14/48\n",
    "118/117 [==============================] - 62s - loss: 0.3019 - acc: 0.8912 - val_loss: 1.6846 - val_acc: 0.4352\n",
    "Epoch 15/48\n",
    "118/117 [==============================] - 62s - loss: 0.2701 - acc: 0.9069 - val_loss: 1.7094 - val_acc: 0.4228\n",
    "Epoch 16/48\n",
    "118/117 [==============================] - 62s - loss: 0.2458 - acc: 0.9174 - val_loss: 1.6392 - val_acc: 0.4753\n",
    "Epoch 17/48\n",
    "118/117 [==============================] - 62s - loss: 0.2236 - acc: 0.9235 - val_loss: 1.7241 - val_acc: 0.4228\n",
    "Epoch 18/48\n",
    "118/117 [==============================] - 62s - loss: 0.1945 - acc: 0.9394 - val_loss: 1.7575 - val_acc: 0.4537\n",
    "Epoch 19/48\n",
    "118/117 [==============================] - 62s - loss: 0.1916 - acc: 0.9396 - val_loss: 1.7809 - val_acc: 0.4290\n",
    "Epoch 20/48\n",
    "118/117 [==============================] - 62s - loss: 0.1666 - acc: 0.9457 - val_loss: 1.6831 - val_acc: 0.4537\n",
    "Epoch 21/48\n",
    "118/117 [==============================] - 63s - loss: 0.1614 - acc: 0.9476 - val_loss: 1.8463 - val_acc: 0.4259\n",
    "Epoch 22/48\n",
    "118/117 [==============================] - 62s - loss: 0.1324 - acc: 0.9603 - val_loss: 1.9625 - val_acc: 0.4352\n",
    "Epoch 23/48\n",
    "118/117 [==============================] - 63s - loss: 0.1235 - acc: 0.9648 - val_loss: 1.8510 - val_acc: 0.4444\n",
    "Epoch 24/48\n",
    "118/117 [==============================] - 62s - loss: 0.1263 - acc: 0.9613 - val_loss: 1.8896 - val_acc: 0.4290\n",
    "Epoch 25/48\n",
    "118/117 [==============================] - 63s - loss: 0.1244 - acc: 0.9595 - val_loss: 1.9483 - val_acc: 0.4383\n",
    "Epoch 26/48\n",
    "118/117 [==============================] - 63s - loss: 0.1006 - acc: 0.9698 - val_loss: 1.9485 - val_acc: 0.4444\n",
    "Epoch 27/48\n",
    "118/117 [==============================] - 63s - loss: 0.0969 - acc: 0.9727 - val_loss: 1.9763 - val_acc: 0.4506\n",
    "Epoch 28/48\n",
    "118/117 [==============================] - 63s - loss: 0.0962 - acc: 0.9711 - val_loss: 1.9766 - val_acc: 0.4691\n",
    "Epoch 29/48\n",
    " 76/117 [==================>...........] - ETA: 21s - loss: 0.0691 - acc: 0.9827"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
